{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "846164dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from string import punctuation\n",
    "import spacy\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel, ldamodel, KeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from plotnine import ggplot, aes, geoms, theme\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "73b8b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data\n",
    "df = pd.read_csv('Data/116th_nonLegislative.csv')\n",
    "\n",
    "# omit procedural speeches\n",
    "df = df.loc[-df.title.str.match(\"TRIBUTE\")]\n",
    "df = df.loc[-df.title.str.match('The SPEAKER pro tempore.*')]\n",
    "df = df.loc[-df.title.str.match('SPECIAL ORDERS.*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35c56abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matched(tx):\n",
    "    \"\"\"\n",
    "    A function to categorize speeches into morning debate, one minutes, or special orders\n",
    "    \"\"\"\n",
    "    \n",
    "    if re.search('(asked and was given permission to address the House for 1 minute and to revise and extend (her|his) remarks)',tx.replace('\\n','')):\n",
    "        return \"one_minute\"\n",
    "    elif re.search(\"The SPEAKER pro tempore.* is recognized for 5 minutes\",tx.replace('\\n','')):\n",
    "        return 'special_order'\n",
    "    elif re.search('The SPEAKER pro tempore.* morning hour debates for 5 minutes',tx.replace('\\n','')):\n",
    "        return 'morning_debate'\n",
    "    else:\n",
    "        return \"None\"\n",
    "    \n",
    "df['category'] = df.text.apply(matched)\n",
    "df_ = df.loc[df.category != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45d7853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Speeches\n",
    "one_minutes = []\n",
    "for row in df.iterrows():\n",
    "    i = row[1]\n",
    "    Text = i.text.replace('\\n','') # remove newlines\n",
    "    \n",
    "    # if a one minute speech\n",
    "    if i.category == 'one_minute':\n",
    "        matched = re.findall(\"(www.gpo.gov\\] *)(.*)( *\\()(.*)( asked .*\\) *)(.*)\",Text)\n",
    "        if matched:\n",
    "            Title = i['title'].split(';')[0]\n",
    "            Speaker = matched[0][3]\n",
    "            Speech = matched[0][-1]\n",
    "            Speech = Speech.replace(Speaker + '. ','')\n",
    "            one_minutes.append({\"Title\":Title,\"Speaker\":Speaker,\"Speech\":Speech,'Category':i.category,'date':i.date})\n",
    "            \n",
    "one_minutes = pd.DataFrame(one_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "684d4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_minutes = one_minutes.loc[one_minutes.Category == 'one_minute']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9bd0e0",
   "metadata": {},
   "source": [
    "### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d3fa2828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [01:14<00:00, 33.60it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "speeches = []\n",
    "for speech in tqdm(one_minutes.Speech):\n",
    "    speech_ = []\n",
    "    for term in nlp(speech):\n",
    "        if term.pos_ in ['NOUN','ADJ','VERB','ADV','PROPN']:\n",
    "            speech_.append(term.lemma_)\n",
    "    speeches.append(speech_)\n",
    "    \n",
    "    \n",
    "vectorizer = TfidfVectorizer(min_df=2,max_df=0.35,use_idf=True)\n",
    "DF = vectorizer.fit_transform([' '.join(speech) for speech in speeches])\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc7bb3",
   "metadata": {},
   "source": [
    "## Get started with TC-W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "55329b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('wiki_200/model.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0598d",
   "metadata": {},
   "source": [
    "### Run model with different num topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f55ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(components,ntop=10):\n",
    "    model = NMF(n_components=25,init='nndsvda',max_iter=1000)\n",
    "    W = model.fit_transform(DF)\n",
    "    H = model.components_\n",
    "    \n",
    "    term_rankings = []\n",
    "    for topic_index in range(H.shape[0]):\n",
    "        top_indices = np.argsort(H[topic_index,:])[::-1]\n",
    "        term_ranking = [terms[i] for i in top_indices[:ntop]]\n",
    "        term_rankings.append(term_ranking)\n",
    "    \n",
    "    \n",
    "    # COMPUTE W2V"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
